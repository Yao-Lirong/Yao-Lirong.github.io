<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <p>Loss Scaling / Gradient Scaling was mentioned in &lt;ahref="#2024/03/01-Mixed-Precision-Training"&gt;Mixed-Precision Training&lt;/a&gt;as one of the 3 techniques, but there are many points to be careful withwhen in practice.</p> <p><span id="more"></span>&lt;h2 id="overview-typical-use-case"&gt;Overview: Typical Use Case&lt;/h2&gt;&lt;p&gt;Here’s an overview of how to use <code>amp.GradScaler</code> adaptedfrom &lt;ahref=”https://pytorch.org/docs/stable/amp.html#gradient-scaling”&gt;PyTorchofficial doc&lt;/a&gt;.&lt;/p&gt;&lt;h3 id="background"&gt;Background&lt;/h3&gt;&lt;p&gt;If the forward pass for a particular op has <code>float16</code>inputs, under &lt;ahref=”https://pytorch.org/docs/stable/amp.html”&gt;Automatic MixedPrecision package - torch.amp&lt;/a&gt;, the backward pass for that op willproduce gradients of the same data type - <code>float16</code> .Gradient values with small magnitudes may not be representable in<code>float16</code>. These values will flush to zero (“underflow”), sothe update for the corresponding parameters will be lost.&lt;/p&gt;&lt;h3 id="code"&gt;Code&lt;/h3&gt;&lt;ol type="1"&gt;&lt;li&gt;<code>scaler.scale(loss).backward()</code>: To prevent underflow,“gradient scaling’ multiplies the network’s loss(es) by a scale factorand invokes a backward pass on the scaled loss(es). In this way, thegradients on all parameters are scaled by this same factor and we don’thave to worry about them flush to zero. <code>scaler.scale(loss)</code>multiplies a given loss by <code>scaler</code>’s current scale factor.We then call backward on this scaled loss.&lt;/li&gt;&lt;li&gt;<code>scaler.step(optimizer)</code>: After back-propagation, alllearnable parameters get their gradients, which are scaled to preventunderflow. Before applying whatever learning algorithm (Adam, SGD, …) onthem, we have to unscale them so the amount to be updated is correct.<code>scaler.step(optimizer)</code> 1. unscales gradients, 2. calls<code>optimizer.step()</code>, and does the previous two points safely:&lt;ol type="1"&gt;&lt;li&gt;Internally invokes <code>unscale_(optimizer)</code> (unless<code>unscale_()</code> was explicitly called for <code>optimizer</code>earlier in the iteration). As part of the <code>unscale_()</code>,gradients are checked for infs/NaNs to prevent overflow/underflow (Forwhy overflow can happen, check point 3 <code>scaler.update</code>)&lt;/li&gt;&lt;li&gt;If no inf/NaN gradients are found, invokes<code>optimizer.step()</code> using the unscaled gradients. Otherwise,<code>optimizer.step()</code> is skipped to avoid corrupting theparams.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;<code>scaler.update()</code>: It would be great if we could justmultiply all gradients by a super big number so absolutely no underflowhappens, but doing so can cause overflow. The scaler estimates a goodscaling factor for each iteration, so neither underflow nor overflowhappens. <code>scaler.update()</code> updates <code>scaler</code>’sscale factor for next iteration.&lt;/li&gt;&lt;/ol&gt;<figure class="highlight python">&lt;table&gt;&lt;tr&gt;&lt;td class="gutter"&gt;&lt;pre&gt;<span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br>&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;<span class="line">scaler = torch.cuda.amp.GradScaler()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> epochs:</span><br><span class="line"> <span class="keyword">for</span> <span class="built_in">input</span>, target <span class="keyword">in</span> data:</span><br><span class="line"> optimizer.zero_grad()</span><br><span class="line"> <span class="keyword">with</span> autocast(device_type=<span class="string">'cuda'</span>, dtype=torch.float16):</span><br><span class="line"> output = model(<span class="built_in">input</span>)</span><br><span class="line"> loss = loss_fn(output, target)</span><br><span class="line"> scaler.scale(loss).backward()</span><br><span class="line"> scaler.step(optimizer)</span><br><span class="line"> scaler.update()</span><br>&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</figure>&lt;h2 id="working-with-unscaled-gradients---gradient-clipping"&gt;&lt;ahref=”https://pytorch.org/docs/stable/notes/amp_examples.html#id4”&gt;Workingwith Unscaled Gradients - Gradient clipping&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;gradient clipping manipulates a set of gradients such that theirglobal norm &lt;ahref=”https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html#torch.nn.utils.clip_grad_norm_”&gt;<code>torch.nn.utils.clip_grad_norm_()</code>&lt;/a&gt;or maximum magnitude &lt;ahref=”https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_value_.html#torch.nn.utils.clip_grad_value_”&gt;<code>torch.nn.utils.clip_grad_value_()</code>&lt;/a&gt;is &lt;= some user-imposed threshold.&lt;/p&gt;&lt;p&gt;The “gradients” here of course refer to the original, unscaledgradients. Therefore, you need to call<code>scaler.unscale_(optimizer)</code> before clipping.&lt;/p&gt;<figure class="highlight python">&lt;table&gt;&lt;tr&gt;&lt;td class="gutter"&gt;&lt;pre&gt;<span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br>&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;<span class="line">scaler = GradScaler()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> epochs:</span><br><span class="line"> <span class="keyword">for</span> <span class="built_in">input</span>, target <span class="keyword">in</span> data:</span><br><span class="line"> optimizer.zero_grad()</span><br><span class="line"> <span class="keyword">with</span> autocast(device_type=<span class="string">'cuda'</span>, dtype=torch.float16):</span><br><span class="line"> output = model(<span class="built_in">input</span>)</span><br><span class="line"> loss = loss_fn(output, target)</span><br><span class="line"> scaler.scale(loss).backward()</span><br><span class="line"></span><br><span class="line"> <span class="comment"># Unscales the gradients of optimizer's assigned params in-place</span></span><br><span class="line"> scaler.unscale_(optimizer)</span><br><span class="line"></span><br><span class="line"> <span class="comment"># Since the gradients of optimizer's assigned params are unscaled, clips as usual:</span></span><br><span class="line"> torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)</span><br><span class="line"></span><br><span class="line"> <span class="comment"># optimizer's gradients are already unscaled, so scaler.step does not unscale them,</span></span><br><span class="line"> <span class="comment"># although it still skips optimizer.step() if the gradients contain infs or NaNs.</span></span><br><span class="line"> scaler.step(optimizer)</span><br><span class="line"></span><br><span class="line"> scaler.update()</span><br>&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</figure>&lt;h2 id="working-with-scaled-gradients---gradient-accumulation"&gt;&lt;ahref=”https://pytorch.org/docs/stable/notes/amp_examples.html#id6”&gt;Workingwith Scaled Gradients - Gradient accumulation&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Gradient accumulation adds gradients over an effective batch of size<code>batch_per_step * gradient_accumulation_steps</code>(<code>* num_procs</code> if distributed). Operations related to scaledgradients should occur at effective batch granularity. The followinghappens at the end of each effective batch:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;inf/NaN checking&lt;/li&gt;&lt;li&gt;step skipping if inf/NaN grads are found&lt;/li&gt;&lt;li&gt;parameter update&lt;/li&gt;&lt;li&gt;scale update&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Within an effective batch, all grads you accumulate should all bescaled and the scale factor should remain unchanged.&lt;/p&gt;<figure class="highlight python">&lt;table&gt;&lt;tr&gt;&lt;td class="gutter"&gt;&lt;pre&gt;<span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br>&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;<span class="line">scaler = GradScaler()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> epochs:</span><br><span class="line"> <span class="keyword">for</span> micro_step <span class="keyword">in</span> <span class="built_in">range</span>(gradient_accumulation_steps):</span><br><span class="line"> <span class="built_in">input</span>, target = get_data(epoch, micro_step)</span><br><span class="line"> <span class="keyword">with</span> autocast(device_type=<span class="string">'cuda'</span>, dtype=torch.float16):</span><br><span class="line"> output = model(<span class="built_in">input</span>)</span><br><span class="line"> loss = loss_fn(output, target)</span><br><span class="line"> loss = loss / gradient_accumulation_steps</span><br><span class="line"> <span class="comment"># Accumulates scaled gradients.</span></span><br><span class="line"> scaler.scale(loss).backward()</span><br><span class="line"> </span><br><span class="line"> <span class="comment"># If you need to work with unscaled gradients, </span></span><br><span class="line"> <span class="comment"># after all (scaled) grads for the upcoming step have been accumulated</span></span><br><span class="line"> <span class="comment"># may unscale_ here if desired (e.g., to allow clipping unscaled gradients)</span></span><br><span class="line"> scaler.step(optimizer)</span><br><span class="line"> scaler.update()</span><br><span class="line"> optimizer.zero_grad()</span><br>&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</figure>&lt;p&gt;<strong>These examples may seem too vanilla, check out &lt;ahref=”https://github.com/karpathy/nanoGPT/blob/325be85d9be8c81b436728a420e85796c57dba7e/train.py#L290-L314”&gt;nanoGPT’smixed precision training loop&lt;/a&gt; for a lively combination of gradientaccumulation and gradient clipping.</strong>&lt;/p&gt;&lt;h2 id="working-with-scaled-gradients---gradient-penalty"&gt;&lt;ahref=”https://pytorch.org/docs/stable/notes/amp_examples.html#id7”&gt;Workingwith Scaled Gradients - Gradient penalty&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;What? Why?&lt;/p&gt;&lt;p&gt;https://discuss.pytorch.org/t/whats-the-use-of-scaled-grad-params-in-this-example-of-gradient-penalty-with-scaled-gradients/199741/3&lt;/p&gt;&lt;h2 id="epilogue"&gt;Epilogue&lt;/h2&gt;&lt;p&gt;This <a href="https://deepgram.com/ai-glossary/gradient-scaling" rel="external nofollow noopener" target="_blank">wikipage from Deepgram</a> provides a detailed view of what gradient scalingis about, but I don’t know why it just reads like AI-generated content.Maybe because it gives too many unnecessary details.&lt;/p&gt;</p> </body></html>