<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <p>We borrow the results of decoder-only transformer models from &lt;ahref="https://arxiv.org/abs/2001.08361"&gt;OpenAI’s paper Scaling Laws forNeural Language Models&lt;/a&gt; Section 2.1</p> <p><span id="more"></span>&lt;p&gt;We use the following notations:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;<span class="math inline"><em>L</em></span> = number of layers oftransformer blocks (<span class="math inline"><em>N</em></span> in &lt;ahref=”https://arxiv.org/pdf/1706.03762.pdf”&gt;Attention is All You Need&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;spanclass=”math inline”&gt;<em>d</em><sub><em>m</em><em>o</em><em>d</em><em>e</em><em>l</em></sub>&lt;/span&gt;= dimension of the input &amp; output of a transformer block, also theoutput of the text encoder and input of the decoder&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;spanclass=”math inline”&gt;<em>d</em><sub><em>f</em><em>f</em></sub>&lt;/span&gt; =dimension of the feed-forward network’s bottleneck. We defined thefeed-forward network as<code>fc1 = fc(d_model, d_ff), fc2 = fc(d_ff, d_model)</code>&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;spanclass=”math inline”&gt;<em>d</em><sub><em>a</em><em>t</em><em>t</em><em>n</em></sub>&lt;/span&gt;= dimension of the multi-head attention output (In &lt;ahref=”https://arxiv.org/pdf/1706.03762.pdf”&gt;Attention is All You Need&lt;/a&gt;,we have <span class="math inline"><em>h</em></span> number of heads.Queries and keys have dimension &lt;spanclass=”math inline”&gt;<em>d</em><sub><em>k</em></sub>&lt;/span&gt;. Values havedimension &lt;spanclass=”math inline”&gt;<em>d</em><sub><em>v</em></sub>&lt;/span&gt;. In practice,we usually have &lt;spanclass=”math inline”&gt;<em>d</em><sub><em>k</em></sub> = <em>d</em><sub><em>v</em></sub>&lt;/span&gt;.&lt;spanclass=”math inline”&gt;<em>d</em><sub><em>a</em><em>t</em><em>t</em><em>n</em></sub>&lt;/span&gt;we have here is defined as &lt;spanclass=”math inline”&gt;<em>d</em><sub><em>k</em></sub> × <em>h</em>&lt;/span&gt;)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;table&gt;&lt;colgroup&gt;&lt;col style="width: 10%" /&gt;&lt;col style="width: 17%" /&gt;&lt;col style="width: 72%" /&gt;&lt;/colgroup&gt;&lt;thead&gt;&lt;tr class="header"&gt;&lt;th&gt;Part&lt;/th&gt;&lt;th&gt;Parameters&lt;/th&gt;&lt;th&gt;Explanation&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr class="odd"&gt;&lt;td&gt;Embed&lt;/td&gt;&lt;td&gt;<span class="math inline">$n_{vocab}\times d_{model} \ +n_{ctx}\times d_{model}$</span>&lt;/td&gt;&lt;td&gt;One word embedding matrix (mapping each token to correspondingembedding ) and one positional embedding matrix&lt;/td&gt;&lt;/tr&gt;&lt;tr class="even"&gt;&lt;td&gt;Attention: Q K V Matrix&lt;/td&gt;&lt;td&gt;&lt;spanclass=”math inline”&gt;<em>L</em>3<em>d</em><sub><em>m</em><em>o</em><em>d</em><em>e</em><em>l</em></sub><em>d</em><sub><em>a</em><em>t</em><em>t</em><em>n</em></sub>&lt;/span&gt;&lt;/td&gt;&lt;td&gt;<span class="math inline"><em>W</em><sub><em>Q</em></sub></span> hasshape &lt;spanclass=”math inline”&gt;(<em>d</em><sub><em>m</em><em>o</em><em>d</em><em>e</em><em>l</em></sub>, <em>d</em><sub><em>a</em><em>t</em><em>t</em><em>n</em></sub>)&lt;/span&gt;.There’re also &lt;spanclass=”math inline”&gt;<em>W</em><sub><em>K</em></sub>&lt;/span&gt; and &lt;spanclass=”math inline”&gt;<em>W</em><sub><em>V</em></sub>&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class="odd"&gt;&lt;td&gt;Attention: Multi-head Projection&lt;/td&gt;&lt;td&gt;$L d_{attn} d_{model} $&lt;/td&gt;&lt;td&gt;After we concat the output from all heads, there’s one projectionfrom all-head output to the final output. This is that matrix. It wasdefined as &lt;spanclass=”math inline”&gt;<em>W</em><sup><em>O</em></sup>&lt;/span&gt; in &lt;ahref=”https://arxiv.org/pdf/1706.03762.pdf”&gt;Attention is All You Need 3.2.2&lt;/a&gt;.&lt;/td&gt;&lt;/tr&gt;&lt;tr class="even"&gt;&lt;td&gt;Feedforward Network&lt;/td&gt;&lt;td&gt;&lt;spanclass=”math inline”&gt;<em>L</em>2<em>d</em><sub><em>m</em><em>o</em><em>d</em><em>e</em><em>l</em></sub><em>d</em><sub><em>f</em><em>f</em></sub>&lt;/span&gt;&lt;/td&gt;&lt;td&gt;Explained in the definition of &lt;spanclass=”math inline”&gt;<em>d</em><sub><em>f</em><em>f</em></sub>&lt;/span&gt; above.&lt;/td&gt;&lt;/tr&gt;&lt;tr class="odd"&gt;&lt;td&gt;Total (Non-Embedding)&lt;/td&gt;&lt;td&gt;&lt;spanclass=”math inline”&gt;2<em>L</em><em>d</em><sub><em>m</em><em>o</em><em>d</em><em>e</em><em>l</em></sub>(2<em>d</em><sub><em>a</em><em>t</em><em>t</em><em>n</em></sub> + <em>d</em><sub><em>f</em><em>f</em></sub>)&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;If we have the standard &lt;spanclass=”math inline”&gt;<em>d</em><sub><em>a</em><em>t</em><em>t</em><em>n</em></sub> = <em>d</em><sub><em>m</em><em>o</em><em>d</em><em>e</em><em>l</em></sub> = <em>d</em><sub><em>f</em><em>f</em></sub>/4&lt;/span&gt;,we can get &lt;spanclass=”math inline”&gt;<em>N</em> = 12<em>L</em><em>d</em><sub><em>m</em><em>o</em><em>d</em><em>e</em><em>l</em></sub><sup>2</sup>&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Put this into practice, let’s calculate a rough estimate of number ofparameters the vanilla transformer has. The vanilla transformer base,per the paper &lt;ahref=”https://arxiv.org/pdf/1706.03762.pdf”&gt;Attention is All You Need Table3&lt;/a&gt;, <span class="math inline"><em>L</em> = 6</span>, &lt;spanclass=”math inline”&gt;<em>d</em><sub><em>m</em><em>o</em><em>d</em><em>e</em><em>l</em></sub> = 512&lt;/span&gt;,&lt;spanclass=”math inline”&gt;<em>d</em><sub><em>f</em><em>f</em></sub> = 2048&lt;/span&gt;,&lt;spanclass=”math inline”&gt;<em>d</em><sub><em>a</em><em>t</em><em>t</em><em>n</em></sub> = <em>h</em> × <em>d</em><sub><em>k</em></sub> = 8 × 64 = 512&lt;/span&gt;,&lt;spanclass=”math inline”&gt;<em>n</em><sub><em>v</em><em>o</em><em>c</em><em>a</em><em>b</em></sub> = 37000&lt;/span&gt;.I didn’t find info about &lt;spanclass=”math inline”&gt;<em>n</em><sub><em>c</em><em>t</em><em>x</em></sub>&lt;/span&gt;,but is probably 512.&lt;/p&gt;&lt;p&gt;Note that different from OpenAI’s favorite decoder-only transformer,the vanilla transformer has an encoder-decoder architecture and thedecoder block has an additional attention block. Therefore, the encoderhas a total &lt;spanclass=”math inline”&gt;2<em>L</em><em>d</em><sub><em>m</em><em>o</em><em>d</em><em>e</em><em>l</em></sub>(2<em>d</em><sub><em>a</em><em>t</em><em>t</em><em>n</em></sub> + <em>d</em><sub><em>f</em><em>f</em></sub>)&lt;/span&gt;parameters, the decoder has a total &lt;spanclass=”math inline”&gt;2<em>L</em><em>d</em><sub><em>m</em><em>o</em><em>d</em><em>e</em><em>l</em></sub>(4<em>d</em><sub><em>a</em><em>t</em><em>t</em><em>n</em></sub> + <em>d</em><sub><em>f</em><em>f</em></sub>)&lt;/span&gt;params, and the embedding part has a total &lt;spanclass=”math inline”&gt;<em>n</em><sub><em>v</em><em>o</em><em>c</em><em>a</em><em>b</em></sub> × <em>d</em><sub><em>m</em><em>o</em><em>d</em><em>e</em><em>l</em></sub> + <em>n</em><sub><em>c</em><em>t</em><em>x</em></sub> × <em>d</em><sub><em>m</em><em>o</em><em>d</em><em>e</em><em>l</em></sub>&lt;/span&gt;params. The final result is &lt;spanclass=”math inline”&gt; ∼ 63 × 10<sup>6</sup>&lt;/span&gt;. I tried hard tofigure out where went off from the paper’s &lt;spanclass=”math inline”&gt;65 × 10<sup>6</sup>&lt;/span&gt; but had no luck. Addingthe parameters of LayerNorm still didn’t even out the numbers. But it’sclose enough so I’ll call it a day.&lt;/p&gt;</p> </body></html>